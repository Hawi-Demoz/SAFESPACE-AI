# Quick Safety Guides

These short, actionable guides help users and moderators quickly address common online safety scenarios. Tailored for SafeSpace AI.

## Featured Guides

<div>
  <p><span style="background:#ffefef;color:#b00000;padding:4px 8px;border-radius:6px;font-weight:600;">How to Document Online Harassment</span> — <em>5 min read</em></p>
  <p><span style="background:#ffefef;color:#b00000;padding:4px 8px;border-radius:6px;font-weight:600;">Securing Your Social Media Profiles</span> — <em>8 min read</em></p>
  <p><span style="background:#ffefef;color:#b00000;padding:4px 8px;border-radius:6px;font-weight:600;">Recognizing Signs of Cyberstalking</span> — <em>6 min read</em></p>
  <p><span style="background:#ffefef;color:#b00000;padding:4px 8px;border-radius:6px;font-weight:600;">Legal Rights Against Digital Abuse</span> — <em>overview</em></p>
</div>

Use these highlighted guides for quick reference. Detailed steps are provided below.

## 1) Spotting Toxic Content Fast
- Watch for slurs, insults, harassment, threats, sexualized degradation, identity attacks.
- Use the extension’s toxicity preview (popup) before posting.
- If flagged high-risk, revise phrasing or choose to not post.

## 2) De-escalation Script (When You’re Targeted)
- Pause and breathe; avoid instant replies.
- Respond neutral: "I disagree. Let’s keep this civil." or "I’m signing off for now."
- Use platform tools: mute, block, report.
- Save evidence: screenshots with timestamps, profile URLs.

## 3) Reporting Harassment Efficiently
- Collect: URLs, usernames, timestamps, full message/thread screenshots.
- Categorize: harassment, hate speech, violent threat, sexual content, spam.
- Submit via platform’s report form. Note policy sections if available.
- Keep your own log in SafeSpace AI’s Evidence page.

## 4) Community Moderator Playbook
- Triage: prioritize threats and hate over general rudeness.
- Action ladder: warn → delete → mute → temporary ban → permanent ban.
- Consistency: apply rules evenly; document decisions.
- Safety first: protect targets; offer resources.

## 5) Personal Safety Settings Checklist
- Privacy: limit DMs; restrict who can tag/mention.
- Filters: enable keyword blocks; auto-hide new accounts.
- Alerts: reduce push notifications for toxic triggers.
- Account security: strong unique passwords; 2FA enabled.

## 6) Evidence Collection Tips (Legal/Support)
- Preserve originals: screenshots + raw text + URLs.
- Capture context: thread history and prior messages.
- Time-sync: use system time and platform timestamps.
- Store securely: use SafeSpace AI’s Evidence with backups.

## 7) Responding to Hate Speech
- Do not engage in kind; avoid counter-insults.
- Use platform policies: cite specific rules in reports.
- Consider bystander support: "This isn’t okay here."
- Prioritize mental health: step away; seek support.

## 8) Crisis/Threat Response
- Immediate danger: contact local authorities.
- Report violent threats to platform mods promptly.
- Document exact wording and sender details.
- Do not share private info publicly.

## 9) Wellbeing & Recovery
- Reduce exposure: mute keywords, take breaks.
- Reach out: friends, support lines, counseling.
- Reflect: adjust boundaries and filters.
- Learn: review guides and update your strategies.

## 10) Using SafeSpace AI Effectively
- Browser extension: highlight likely toxic content before posting.
- Dashboard: monitor flagged interactions and risk levels.
- Evidence: save screenshots and notes with timestamps.
- Resources: find help in the app’s Resources page.

---

### Quick Links
- Evidence Page: app sidebar → "Evidence"
- Resources Page: app sidebar → "Resources"
- Extension Popup: browser toolbar → SafeSpace AI icon

If you have scenarios to add, open an issue or edit this document.